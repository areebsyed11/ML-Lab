{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bf043b1-7940-4bdc-b6e6-c23a891bb5fb",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f69711fd-91e7-40d6-9d76-073009d78d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8ec3e782-bbd7-4dcc-95db-b24f865d8639",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('heart.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3e67fb8b-ce11-4aaf-a220-d3c2ac1cbdb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1025 entries, 0 to 1024\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       1025 non-null   int64  \n",
      " 1   sex       1025 non-null   int64  \n",
      " 2   cp        1025 non-null   int64  \n",
      " 3   trestbps  1025 non-null   int64  \n",
      " 4   chol      1025 non-null   int64  \n",
      " 5   fbs       1025 non-null   int64  \n",
      " 6   restecg   1025 non-null   int64  \n",
      " 7   thalach   1025 non-null   int64  \n",
      " 8   exang     1025 non-null   int64  \n",
      " 9   oldpeak   1025 non-null   float64\n",
      " 10  slope     1025 non-null   int64  \n",
      " 11  ca        1025 non-null   int64  \n",
      " 12  thal      1025 non-null   int64  \n",
      " 13  target    1025 non-null   int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 112.2 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b3692c69-2fcb-4fb0-ae69-daa1cca6d0e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.00000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.434146</td>\n",
       "      <td>0.695610</td>\n",
       "      <td>0.942439</td>\n",
       "      <td>131.611707</td>\n",
       "      <td>246.00000</td>\n",
       "      <td>0.149268</td>\n",
       "      <td>0.529756</td>\n",
       "      <td>149.114146</td>\n",
       "      <td>0.336585</td>\n",
       "      <td>1.071512</td>\n",
       "      <td>1.385366</td>\n",
       "      <td>0.754146</td>\n",
       "      <td>2.323902</td>\n",
       "      <td>0.513171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.072290</td>\n",
       "      <td>0.460373</td>\n",
       "      <td>1.029641</td>\n",
       "      <td>17.516718</td>\n",
       "      <td>51.59251</td>\n",
       "      <td>0.356527</td>\n",
       "      <td>0.527878</td>\n",
       "      <td>23.005724</td>\n",
       "      <td>0.472772</td>\n",
       "      <td>1.175053</td>\n",
       "      <td>0.617755</td>\n",
       "      <td>1.030798</td>\n",
       "      <td>0.620660</td>\n",
       "      <td>0.500070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>211.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>240.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>275.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age          sex           cp     trestbps        chol  \\\n",
       "count  1025.000000  1025.000000  1025.000000  1025.000000  1025.00000   \n",
       "mean     54.434146     0.695610     0.942439   131.611707   246.00000   \n",
       "std       9.072290     0.460373     1.029641    17.516718    51.59251   \n",
       "min      29.000000     0.000000     0.000000    94.000000   126.00000   \n",
       "25%      48.000000     0.000000     0.000000   120.000000   211.00000   \n",
       "50%      56.000000     1.000000     1.000000   130.000000   240.00000   \n",
       "75%      61.000000     1.000000     2.000000   140.000000   275.00000   \n",
       "max      77.000000     1.000000     3.000000   200.000000   564.00000   \n",
       "\n",
       "               fbs      restecg      thalach        exang      oldpeak  \\\n",
       "count  1025.000000  1025.000000  1025.000000  1025.000000  1025.000000   \n",
       "mean      0.149268     0.529756   149.114146     0.336585     1.071512   \n",
       "std       0.356527     0.527878    23.005724     0.472772     1.175053   \n",
       "min       0.000000     0.000000    71.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000   132.000000     0.000000     0.000000   \n",
       "50%       0.000000     1.000000   152.000000     0.000000     0.800000   \n",
       "75%       0.000000     1.000000   166.000000     1.000000     1.800000   \n",
       "max       1.000000     2.000000   202.000000     1.000000     6.200000   \n",
       "\n",
       "             slope           ca         thal       target  \n",
       "count  1025.000000  1025.000000  1025.000000  1025.000000  \n",
       "mean      1.385366     0.754146     2.323902     0.513171  \n",
       "std       0.617755     1.030798     0.620660     0.500070  \n",
       "min       0.000000     0.000000     0.000000     0.000000  \n",
       "25%       1.000000     0.000000     2.000000     0.000000  \n",
       "50%       1.000000     0.000000     2.000000     1.000000  \n",
       "75%       2.000000     1.000000     3.000000     1.000000  \n",
       "max       2.000000     4.000000     3.000000     1.000000  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "4b562b0e-3181-46cd-8a28-3f26aec34c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age         0\n",
      "sex         0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalach     0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          0\n",
      "thal        0\n",
      "target      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "641956b7-d86c-4ee4-9799-3b78e1515198",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "results = []\n",
    "\n",
    "\n",
    "# L1 regularization\n",
    "\n",
    "model_l1 = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "\n",
    "model_l1.fit(X_train, y_train)\n",
    "train_acc_l1 = accuracy_score(y_train, model_l1.predict(X_train))\n",
    "test_acc_l1 = accuracy_score(y_test, model_l1.predict(X_test))\n",
    "\n",
    "results.append({'Penalty': 'L1', 'Training Accuracy': train_acc_l1, 'Testing Accuracy': test_acc_l1})\n",
    "\n",
    "\n",
    "# L2 regularization\n",
    "\n",
    "model_l2 = LogisticRegression(penalty='l2', solver='lbfgs')\n",
    "\n",
    "model_l2.fit(X_train, y_train)\n",
    "train_acc_l2 = accuracy_score(y_train, model_l2.predict(X_train))\n",
    "test_acc_l2 = accuracy_score(y_test, model_l2.predict(X_test))\n",
    "\n",
    "results.append({'Penalty': 'L2', 'Training Accuracy': train_acc_l2, 'Testing Accuracy': test_acc_l2})\n",
    "\n",
    "\n",
    "# Elastic Net regularization\n",
    "\n",
    "model_elasticnet = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5)\n",
    "\n",
    "model_elasticnet.fit(X_train, y_train)\n",
    "train_acc_elasticnet = accuracy_score(y_train, model_elasticnet.predict(X_train))\n",
    "test_acc_elasticnet = accuracy_score(y_test, model_elasticnet.predict(X_test))\n",
    "results.append({'Penalty': 'Elastic Net', 'Training Accuracy': train_acc_elasticnet, 'Testing Accuracy': test_acc_elasticnet})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "91f5b6f4-99f7-44e0-b0a2-9d4cf7ab664f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All Training and Testing Accuracies:\n",
      "       Penalty  Training Accuracy  Testing Accuracy\n",
      "0           L1           0.871951          0.795122\n",
      "1           L2           0.871951          0.795122\n",
      "2  Elastic Net           0.871951          0.795122\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nAll Training and Testing Accuracies:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "76c0fb54-cb9c-42a1-b5cc-5173e154a180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erors:\n",
    "# Not all solvers support all penalties. e.g For L1: liblinear works well, while lbfgs does not.\n",
    "# For Elastic Net: saga is required and l1_ratio must also be specified.\n",
    "\n",
    "# Parameter Changed:\n",
    "# For Elastic Net, the l1_ratio can be tuned as it handles the balance between L1 and L2 regularization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da9bba4-f865-4cf0-8c5f-2adc839b02e0",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "24dcefa3-47fe-428c-881e-485d7e8b9830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Solver  Training Accuracy  Testing Accuracy\n",
      "0            lbfgs           0.975000          1.000000\n",
      "1        liblinear           0.958333          1.000000\n",
      "2        newton-cg           0.975000          1.000000\n",
      "3  newton-cholesky           0.950000          0.966667\n",
      "4              sag           0.983333          1.000000\n",
      "5             saga           0.975000          1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "solvers = ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']\n",
    "results = []\n",
    "\n",
    "for s in solvers:\n",
    "    model = LogisticRegression(solver=s)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    train_accuracy = accuracy_score(y_train, model.predict(X_train))\n",
    "    test_accuracy = accuracy_score(y_test, model.predict(X_test))\n",
    "\n",
    "    results.append({'Solver': s, 'Training Accuracy': train_accuracy, 'Testing Accuracy': test_accuracy})\n",
    "    \n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "669d87ea-d715-4088-97c9-cb6ad6d791b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Effect of solver:\n",
    "\n",
    "# The training and testing accuracy vary depending on the solver used.\n",
    "# liblinear is better for smaller datasets, lbfgs and newton-cg perform well with medium sized datasets, while saga and sag are designed for large datasets.\n",
    "# sag is the best in my case, giving the highest training and testing accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "73835958-90e7-43eb-b2dd-fa6bb4a66880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Solver  Training Accuracy  Testing Accuracy\n",
      "0            lbfgs           0.871951          0.795122\n",
      "1        liblinear           0.871951          0.795122\n",
      "2        newton-cg           0.871951          0.795122\n",
      "3  newton-cholesky           0.871951          0.795122\n",
      "4              sag           0.871951          0.795122\n",
      "5             saga           0.871951          0.795122\n"
     ]
    }
   ],
   "source": [
    "# Testing on heart dataset\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = pd.read_csv('heart.csv')\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "results_heart = []\n",
    "\n",
    "for s in solvers:\n",
    "    \n",
    "    model = LogisticRegression(solver=s, penalty='l2', max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    train_accuracy = accuracy_score(y_train, model.predict(X_train))\n",
    "    test_accuracy = accuracy_score(y_test, model.predict(X_test))\n",
    "\n",
    "    results_heart.append({'Solver': s, 'Training Accuracy': train_accuracy, 'Testing Accuracy': test_accuracy})\n",
    "\n",
    "\n",
    "results_heart_df = pd.DataFrame(results_heart)\n",
    "print(results_heart_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "933151b6-1b50-495c-b0ee-4500f49f9996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Effect on heart dataset\n",
    "\n",
    "# All solvers give the same training and testing accuracy on heart dataset so yes it is affected by the size of datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dfdc18-f87b-44dd-b12c-44d3f5fff147",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e0bb2fbf-bd36-41df-96c3-345de3ae3c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Result:\n",
      "Training Accuracy: 0.975\n",
      "Testing Accuracy: 1.0\n",
      "\n",
      "Perceptron Result:\n",
      "Training Accuracy: 0.675\n",
      "Testing Accuracy: 0.6333333333333333\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Model\n",
    "lr_model = LogisticRegression(solver='lbfgs')\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "lr_train_acc = accuracy_score(y_train, lr_model.predict(X_train))\n",
    "lr_test_acc = accuracy_score(y_test, lr_model.predict(X_test))\n",
    "print(\"Logistic Regression Result:\")\n",
    "print(f\"Training Accuracy: {lr_train_acc:}\")\n",
    "print(f\"Testing Accuracy: {lr_test_acc:}\")\n",
    "\n",
    "# Perceptron Model\n",
    "perc_model = Perceptron(max_iter=1000, random_state=42)\n",
    "perc_model.fit(X_train, y_train)\n",
    "\n",
    "perc_train_acc = accuracy_score(y_train, perc_model.predict(X_train))\n",
    "perc_test_acc = accuracy_score(y_test, perc_model.predict(X_test))\n",
    "print(\"\\nPerceptron Result:\")\n",
    "print(f\"Training Accuracy: {perc_train_acc:}\")\n",
    "print(f\"Testing Accuracy: {perc_test_acc:}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "6080e265-6e4b-437f-9962-ba4c0dbcbd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference between Perceptron and Logistic Regression\n",
    "\n",
    "# Logistic Regressio performs better on multiclass classification problems like this Iris dataset,\n",
    "# Perceptron is a linear classifier so it doesnt perform well with data that isn't linearly separable.\n",
    "# This results in Perceptron giving lower training and testing accuracy on this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce752e0-9b79-4342-aa93-136b4ae100d2",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "bb721a07-73d7-43bd-84fc-19afb8918d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "8521ef38-0cab-4ec7-85ea-36cb8149f136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   Profession          10000 non-null  object\n",
      " 1   Income              10000 non-null  int64 \n",
      " 2   Credit_card_number  10000 non-null  int64 \n",
      " 3   Expiry              10000 non-null  object\n",
      " 4   Security_code       10000 non-null  int64 \n",
      " 5   Fraud               10000 non-null  int64 \n",
      "dtypes: int64(4), object(2)\n",
      "memory usage: 468.9+ KB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('fraud_detection.csv')\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "35396772-4311-4eaf-8f7d-54c62201eda4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Profession</th>\n",
       "      <th>Income</th>\n",
       "      <th>Credit_card_number</th>\n",
       "      <th>Expiry</th>\n",
       "      <th>Security_code</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DOCTOR</td>\n",
       "      <td>42509</td>\n",
       "      <td>3515418493460774</td>\n",
       "      <td>07/25</td>\n",
       "      <td>251</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DOCTOR</td>\n",
       "      <td>80334</td>\n",
       "      <td>213134223583196</td>\n",
       "      <td>05/32</td>\n",
       "      <td>858</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LAWYER</td>\n",
       "      <td>91552</td>\n",
       "      <td>4869615013764888</td>\n",
       "      <td>03/30</td>\n",
       "      <td>755</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LAWYER</td>\n",
       "      <td>43623</td>\n",
       "      <td>341063356109385</td>\n",
       "      <td>01/29</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DOCTOR</td>\n",
       "      <td>22962</td>\n",
       "      <td>4707418777543978402</td>\n",
       "      <td>11/30</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Profession  Income   Credit_card_number Expiry  Security_code  Fraud\n",
       "0     DOCTOR   42509     3515418493460774  07/25            251      1\n",
       "1     DOCTOR   80334      213134223583196  05/32            858      1\n",
       "2     LAWYER   91552     4869615013764888  03/30            755      1\n",
       "3     LAWYER   43623      341063356109385  01/29            160      1\n",
       "4     DOCTOR   22962  4707418777543978402  11/30            102      0"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "a78222b2-5cee-4588-820b-982c2f00794c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Credit_card_number</th>\n",
       "      <th>Security_code</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>49761.20600</td>\n",
       "      <td>3.851363e+17</td>\n",
       "      <td>863.587800</td>\n",
       "      <td>0.501600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>28837.72928</td>\n",
       "      <td>1.257950e+18</td>\n",
       "      <td>1484.424959</td>\n",
       "      <td>0.500022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>6.040296e+10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>24863.75000</td>\n",
       "      <td>1.800137e+14</td>\n",
       "      <td>275.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>49483.00000</td>\n",
       "      <td>3.512440e+15</td>\n",
       "      <td>539.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>74483.00000</td>\n",
       "      <td>4.594779e+15</td>\n",
       "      <td>813.250000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>99986.00000</td>\n",
       "      <td>4.999697e+18</td>\n",
       "      <td>9990.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Income  Credit_card_number  Security_code         Fraud\n",
       "count  10000.00000        1.000000e+04   10000.000000  10000.000000\n",
       "mean   49761.20600        3.851363e+17     863.587800      0.501600\n",
       "std    28837.72928        1.257950e+18    1484.424959      0.500022\n",
       "min        1.00000        6.040296e+10       0.000000      0.000000\n",
       "25%    24863.75000        1.800137e+14     275.000000      0.000000\n",
       "50%    49483.00000        3.512440e+15     539.500000      1.000000\n",
       "75%    74483.00000        4.594779e+15     813.250000      1.000000\n",
       "max    99986.00000        4.999697e+18    9990.000000      1.000000"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "a83788bb-facf-494f-8e73-79c66788dbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['Credit_card_number', 'Expiry'], axis=1)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "data['Profession'] = label_encoder.fit_transform(data['Profession'])\n",
    "\n",
    "X = data.drop('Fraud', axis=1)\n",
    "y = data['Fraud']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b266c2ac-e708-4e4e-b376-552b7ee99019",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4995 - loss: 0.6971 - val_accuracy: 0.4844 - val_loss: 0.6944\n",
      "Epoch 2/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - accuracy: 0.5089 - loss: 0.6931 - val_accuracy: 0.5075 - val_loss: 0.6942\n",
      "Epoch 3/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - accuracy: 0.5131 - loss: 0.6928 - val_accuracy: 0.4894 - val_loss: 0.6958\n",
      "Epoch 4/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5197 - loss: 0.6925 - val_accuracy: 0.5200 - val_loss: 0.6939\n",
      "Epoch 5/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5156 - loss: 0.6930 - val_accuracy: 0.5125 - val_loss: 0.6940\n",
      "Epoch 6/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step - accuracy: 0.5189 - loss: 0.6915 - val_accuracy: 0.5006 - val_loss: 0.6940\n",
      "Epoch 7/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - accuracy: 0.5144 - loss: 0.6930 - val_accuracy: 0.5106 - val_loss: 0.6932\n",
      "Epoch 8/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - accuracy: 0.5334 - loss: 0.6912 - val_accuracy: 0.5200 - val_loss: 0.6938\n",
      "Epoch 9/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - accuracy: 0.5148 - loss: 0.6927 - val_accuracy: 0.5038 - val_loss: 0.6931\n",
      "Epoch 10/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - accuracy: 0.5108 - loss: 0.6916 - val_accuracy: 0.4956 - val_loss: 0.6933\n",
      "Epoch 11/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - accuracy: 0.5222 - loss: 0.6915 - val_accuracy: 0.5106 - val_loss: 0.6931\n",
      "Epoch 12/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.5263 - loss: 0.6912 - val_accuracy: 0.5063 - val_loss: 0.6937\n",
      "Epoch 13/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - accuracy: 0.5244 - loss: 0.6910 - val_accuracy: 0.5056 - val_loss: 0.6931\n",
      "Epoch 14/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - accuracy: 0.5296 - loss: 0.6902 - val_accuracy: 0.5006 - val_loss: 0.6942\n",
      "Epoch 15/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - accuracy: 0.5177 - loss: 0.6927 - val_accuracy: 0.5094 - val_loss: 0.6931\n",
      "Epoch 16/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - accuracy: 0.5236 - loss: 0.6918 - val_accuracy: 0.5094 - val_loss: 0.6925\n",
      "Epoch 17/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - accuracy: 0.5144 - loss: 0.6919 - val_accuracy: 0.5194 - val_loss: 0.6930\n",
      "Epoch 18/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - accuracy: 0.5235 - loss: 0.6911 - val_accuracy: 0.5100 - val_loss: 0.6928\n",
      "Epoch 19/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - accuracy: 0.5344 - loss: 0.6910 - val_accuracy: 0.5125 - val_loss: 0.6939\n",
      "Epoch 20/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - accuracy: 0.5250 - loss: 0.6925 - val_accuracy: 0.5113 - val_loss: 0.6935\n",
      "Epoch 21/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - accuracy: 0.5301 - loss: 0.6914 - val_accuracy: 0.5131 - val_loss: 0.6941\n",
      "Epoch 22/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - accuracy: 0.5361 - loss: 0.6897 - val_accuracy: 0.5031 - val_loss: 0.6931\n",
      "Epoch 23/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - accuracy: 0.5276 - loss: 0.6913 - val_accuracy: 0.4994 - val_loss: 0.6938\n",
      "Epoch 24/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - accuracy: 0.5119 - loss: 0.6932 - val_accuracy: 0.5075 - val_loss: 0.6991\n",
      "Epoch 25/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 0.5262 - loss: 0.6907 - val_accuracy: 0.4994 - val_loss: 0.6953\n",
      "Epoch 26/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - accuracy: 0.5183 - loss: 0.6926 - val_accuracy: 0.5025 - val_loss: 0.6939\n",
      "Epoch 27/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5248 - loss: 0.6911 - val_accuracy: 0.5100 - val_loss: 0.6951\n",
      "Epoch 28/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.5328 - loss: 0.6906 - val_accuracy: 0.5094 - val_loss: 0.6937\n",
      "Epoch 29/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 0.5355 - loss: 0.6896 - val_accuracy: 0.5106 - val_loss: 0.6942\n",
      "Epoch 30/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - accuracy: 0.5328 - loss: 0.6909 - val_accuracy: 0.5163 - val_loss: 0.6946\n",
      "Epoch 31/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - accuracy: 0.5313 - loss: 0.6911 - val_accuracy: 0.5081 - val_loss: 0.6940\n",
      "Epoch 32/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - accuracy: 0.5353 - loss: 0.6896 - val_accuracy: 0.5144 - val_loss: 0.6942\n",
      "Epoch 33/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.5251 - loss: 0.6916 - val_accuracy: 0.5075 - val_loss: 0.6945\n",
      "Epoch 34/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.5222 - loss: 0.6909 - val_accuracy: 0.4994 - val_loss: 0.6944\n",
      "Epoch 35/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - accuracy: 0.5389 - loss: 0.6897 - val_accuracy: 0.5088 - val_loss: 0.6954\n",
      "Epoch 36/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - accuracy: 0.5244 - loss: 0.6899 - val_accuracy: 0.5081 - val_loss: 0.6941\n",
      "Epoch 37/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - accuracy: 0.5338 - loss: 0.6916 - val_accuracy: 0.5144 - val_loss: 0.6952\n",
      "Epoch 38/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - accuracy: 0.5427 - loss: 0.6886 - val_accuracy: 0.5100 - val_loss: 0.6936\n",
      "Epoch 39/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - accuracy: 0.5349 - loss: 0.6910 - val_accuracy: 0.5106 - val_loss: 0.6958\n",
      "Epoch 40/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - accuracy: 0.5322 - loss: 0.6903 - val_accuracy: 0.5131 - val_loss: 0.6946\n",
      "Epoch 41/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - accuracy: 0.5378 - loss: 0.6908 - val_accuracy: 0.5038 - val_loss: 0.6961\n",
      "Epoch 42/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - accuracy: 0.5305 - loss: 0.6907 - val_accuracy: 0.5100 - val_loss: 0.6960\n",
      "Epoch 43/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - accuracy: 0.5310 - loss: 0.6889 - val_accuracy: 0.5181 - val_loss: 0.6942\n",
      "Epoch 44/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step - accuracy: 0.5459 - loss: 0.6878 - val_accuracy: 0.5175 - val_loss: 0.6945\n",
      "Epoch 45/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - accuracy: 0.5310 - loss: 0.6899 - val_accuracy: 0.5069 - val_loss: 0.6954\n",
      "Epoch 46/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - accuracy: 0.5232 - loss: 0.6918 - val_accuracy: 0.5056 - val_loss: 0.6972\n",
      "Epoch 47/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - accuracy: 0.5433 - loss: 0.6888 - val_accuracy: 0.5031 - val_loss: 0.6946\n",
      "Epoch 48/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5297 - loss: 0.6904 - val_accuracy: 0.5075 - val_loss: 0.6958\n",
      "Epoch 49/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step - accuracy: 0.5364 - loss: 0.6881 - val_accuracy: 0.5094 - val_loss: 0.6958\n",
      "Epoch 50/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - accuracy: 0.5245 - loss: 0.6902 - val_accuracy: 0.5188 - val_loss: 0.6961\n",
      "\n",
      "Model Evaluation on Test Data:\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636us/step - accuracy: 0.5014 - loss: 0.7020\n",
      "Test Loss: 0.6996391415596008\n",
      "Test Accuracy: 0.49300000071525574\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step\n",
      "Accuracy: 0.493\n",
      "Precision: 0.49431230610134436\n",
      "Recall: 0.4765702891326022\n",
      "F1 Score: 0.4852791878172589\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_dim=X_train.shape[1])) # Hidden Layer 1\n",
    "model.add(Dense(64, activation='tanh')) # Hidden Layer 2\n",
    "model.add(Dense(32, activation='relu')) # Hidden Layer 3\n",
    "model.add(Dense(1, activation='sigmoid')) # Output Layer (Binary)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "\n",
    "print(\"\\nModel Evaluation on Test Data:\")\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4998792d-c6f5-45e1-ac1e-4fbe2cf620fd",
   "metadata": {},
   "source": [
    "# Task 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4213b833-9632-4242-900d-1a54472c490e",
   "metadata": {},
   "source": [
    "## Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "86e84b7c-552b-450d-94ca-4d183cc6554b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "34140391-38fc-4627-aff0-cea4ef1d1b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1143 entries, 0 to 1142\n",
      "Data columns (total 13 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         1143 non-null   float64\n",
      " 1   volatile acidity      1143 non-null   float64\n",
      " 2   citric acid           1143 non-null   float64\n",
      " 3   residual sugar        1143 non-null   float64\n",
      " 4   chlorides             1143 non-null   float64\n",
      " 5   free sulfur dioxide   1143 non-null   float64\n",
      " 6   total sulfur dioxide  1143 non-null   float64\n",
      " 7   density               1143 non-null   float64\n",
      " 8   pH                    1143 non-null   float64\n",
      " 9   sulphates             1143 non-null   float64\n",
      " 10  alcohol               1143 non-null   float64\n",
      " 11  quality               1143 non-null   int64  \n",
      " 12  Id                    1143 non-null   int64  \n",
      "dtypes: float64(11), int64(2)\n",
      "memory usage: 116.2 KB\n"
     ]
    }
   ],
   "source": [
    "wine_data = pd.read_csv(\"WineQT.csv\")\n",
    "\n",
    "wine_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "4fb90f67-c54b-4d0c-9abc-6a10d18a36aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  Id  \n",
       "0      9.4        5   0  \n",
       "1      9.8        5   1  \n",
       "2      9.8        5   2  \n",
       "3      9.8        6   3  \n",
       "4      9.4        5   4  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "8c6ad6ad-a1f1-42af-ab53-6c48e516c7f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.311111</td>\n",
       "      <td>0.531339</td>\n",
       "      <td>0.268364</td>\n",
       "      <td>2.532152</td>\n",
       "      <td>0.086933</td>\n",
       "      <td>15.615486</td>\n",
       "      <td>45.914698</td>\n",
       "      <td>0.996730</td>\n",
       "      <td>3.311015</td>\n",
       "      <td>0.657708</td>\n",
       "      <td>10.442111</td>\n",
       "      <td>5.657043</td>\n",
       "      <td>804.969379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.747595</td>\n",
       "      <td>0.179633</td>\n",
       "      <td>0.196686</td>\n",
       "      <td>1.355917</td>\n",
       "      <td>0.047267</td>\n",
       "      <td>10.250486</td>\n",
       "      <td>32.782130</td>\n",
       "      <td>0.001925</td>\n",
       "      <td>0.156664</td>\n",
       "      <td>0.170399</td>\n",
       "      <td>1.082196</td>\n",
       "      <td>0.805824</td>\n",
       "      <td>463.997116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.990070</td>\n",
       "      <td>2.740000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.100000</td>\n",
       "      <td>0.392500</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.995570</td>\n",
       "      <td>3.205000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>411.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>0.996680</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>794.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.100000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>0.997845</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1209.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.900000</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>1.003690</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1597.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count    1143.000000       1143.000000  1143.000000     1143.000000   \n",
       "mean        8.311111          0.531339     0.268364        2.532152   \n",
       "std         1.747595          0.179633     0.196686        1.355917   \n",
       "min         4.600000          0.120000     0.000000        0.900000   \n",
       "25%         7.100000          0.392500     0.090000        1.900000   \n",
       "50%         7.900000          0.520000     0.250000        2.200000   \n",
       "75%         9.100000          0.640000     0.420000        2.600000   \n",
       "max        15.900000          1.580000     1.000000       15.500000   \n",
       "\n",
       "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
       "count  1143.000000          1143.000000           1143.000000  1143.000000   \n",
       "mean      0.086933            15.615486             45.914698     0.996730   \n",
       "std       0.047267            10.250486             32.782130     0.001925   \n",
       "min       0.012000             1.000000              6.000000     0.990070   \n",
       "25%       0.070000             7.000000             21.000000     0.995570   \n",
       "50%       0.079000            13.000000             37.000000     0.996680   \n",
       "75%       0.090000            21.000000             61.000000     0.997845   \n",
       "max       0.611000            68.000000            289.000000     1.003690   \n",
       "\n",
       "                pH    sulphates      alcohol      quality           Id  \n",
       "count  1143.000000  1143.000000  1143.000000  1143.000000  1143.000000  \n",
       "mean      3.311015     0.657708    10.442111     5.657043   804.969379  \n",
       "std       0.156664     0.170399     1.082196     0.805824   463.997116  \n",
       "min       2.740000     0.330000     8.400000     3.000000     0.000000  \n",
       "25%       3.205000     0.550000     9.500000     5.000000   411.000000  \n",
       "50%       3.310000     0.620000    10.200000     6.000000   794.000000  \n",
       "75%       3.400000     0.730000    11.100000     6.000000  1209.500000  \n",
       "max       4.010000     2.000000    14.900000     8.000000  1597.000000  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "0ff84566-62db-49e2-b355-8a8340cf3c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_data = wine_data.drop(columns=[\"Id\"]) \n",
    "wine_features = wine_data.drop(columns=[\"quality\"])\n",
    "wine_target = wine_data[\"quality\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "73334aa5-1859-4d42-a765-7862861a5867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding for multi class classification\n",
    "wine_target = to_categorical(wine_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "ac00c6d4-3d5a-4cf1-9f73-ffaa3aae7f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "wine_features = scaler.fit_transform(wine_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "16fe18f1-5731-4d71-a7cd-7f9fc3eb7a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(wine_features, wine_target, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "628f954e-93a8-4ebd-b9e4-146e99bdbf9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3313 - loss: 1.9119 - val_accuracy: 0.5574 - val_loss: 1.2115\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5530 - loss: 1.1885 - val_accuracy: 0.5956 - val_loss: 1.0197\n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5894 - loss: 1.1010 - val_accuracy: 0.5410 - val_loss: 1.0147\n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6501 - loss: 0.9353 - val_accuracy: 0.5738 - val_loss: 0.9923\n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6086 - loss: 0.9503 - val_accuracy: 0.5738 - val_loss: 0.9841\n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6481 - loss: 0.9212 - val_accuracy: 0.5464 - val_loss: 0.9885\n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6460 - loss: 0.8812 - val_accuracy: 0.5847 - val_loss: 0.9890\n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6453 - loss: 0.8727 - val_accuracy: 0.5683 - val_loss: 1.0137\n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6311 - loss: 0.8527 - val_accuracy: 0.5738 - val_loss: 0.9858\n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6763 - loss: 0.8076 - val_accuracy: 0.5956 - val_loss: 0.9950\n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6660 - loss: 0.8167 - val_accuracy: 0.6066 - val_loss: 1.0072\n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7109 - loss: 0.7582 - val_accuracy: 0.5738 - val_loss: 1.0357\n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6468 - loss: 0.8348 - val_accuracy: 0.5902 - val_loss: 1.0244\n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6937 - loss: 0.7532 - val_accuracy: 0.5847 - val_loss: 1.0335\n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6832 - loss: 0.7906 - val_accuracy: 0.5738 - val_loss: 1.0756\n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6691 - loss: 0.7897 - val_accuracy: 0.5683 - val_loss: 1.0375\n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6616 - loss: 0.8039 - val_accuracy: 0.6011 - val_loss: 1.0206\n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7090 - loss: 0.7281 - val_accuracy: 0.6120 - val_loss: 1.0396\n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6908 - loss: 0.7756 - val_accuracy: 0.5738 - val_loss: 1.0379\n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6977 - loss: 0.7324 - val_accuracy: 0.5902 - val_loss: 1.0359\n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7058 - loss: 0.7429 - val_accuracy: 0.5902 - val_loss: 1.0541\n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7098 - loss: 0.7226 - val_accuracy: 0.5847 - val_loss: 1.0524\n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7253 - loss: 0.6765 - val_accuracy: 0.5738 - val_loss: 1.0844\n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7190 - loss: 0.6982 - val_accuracy: 0.5847 - val_loss: 1.0886\n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7200 - loss: 0.6646 - val_accuracy: 0.5956 - val_loss: 1.0657\n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7099 - loss: 0.6911 - val_accuracy: 0.5628 - val_loss: 1.0880\n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7251 - loss: 0.6558 - val_accuracy: 0.5628 - val_loss: 1.0877\n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7312 - loss: 0.6589 - val_accuracy: 0.5902 - val_loss: 1.1049\n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7425 - loss: 0.6104 - val_accuracy: 0.5902 - val_loss: 1.1252\n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7218 - loss: 0.6741 - val_accuracy: 0.5738 - val_loss: 1.1482\n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7499 - loss: 0.6210 - val_accuracy: 0.5628 - val_loss: 1.1751\n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7275 - loss: 0.6212 - val_accuracy: 0.5956 - val_loss: 1.1382\n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7388 - loss: 0.6077 - val_accuracy: 0.5519 - val_loss: 1.1478\n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7196 - loss: 0.6307 - val_accuracy: 0.5792 - val_loss: 1.1508\n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7514 - loss: 0.6195 - val_accuracy: 0.5956 - val_loss: 1.1790\n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7407 - loss: 0.5985 - val_accuracy: 0.5847 - val_loss: 1.1459\n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7589 - loss: 0.5786 - val_accuracy: 0.5410 - val_loss: 1.1870\n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7477 - loss: 0.5657 - val_accuracy: 0.5683 - val_loss: 1.1840\n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7435 - loss: 0.5875 - val_accuracy: 0.5628 - val_loss: 1.2511\n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7549 - loss: 0.5800 - val_accuracy: 0.5191 - val_loss: 1.2256\n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7822 - loss: 0.5366 - val_accuracy: 0.5847 - val_loss: 1.2344\n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7730 - loss: 0.5256 - val_accuracy: 0.5683 - val_loss: 1.2476\n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8091 - loss: 0.5128 - val_accuracy: 0.5355 - val_loss: 1.3161\n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8001 - loss: 0.4915 - val_accuracy: 0.5519 - val_loss: 1.3707\n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7967 - loss: 0.5142 - val_accuracy: 0.5464 - val_loss: 1.2943\n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7990 - loss: 0.5231 - val_accuracy: 0.5956 - val_loss: 1.3078\n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8210 - loss: 0.4955 - val_accuracy: 0.5738 - val_loss: 1.3300\n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8219 - loss: 0.4762 - val_accuracy: 0.5792 - val_loss: 1.3048\n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8074 - loss: 0.5084 - val_accuracy: 0.5956 - val_loss: 1.3403\n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8218 - loss: 0.4653 - val_accuracy: 0.5519 - val_loss: 1.3929\n",
      "\n",
      "Model Evaluation on Test Data:\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6220 - loss: 1.2366\n",
      "Test Loss: 1.1737836599349976\n",
      "Test Accuracy: 0.624454140663147\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Accuracy: 0.6244541484716157\n",
      "Precision: 0.622237756845247\n",
      "Recall: 0.6244541484716157\n",
      "F1 Score: 0.6121163343158814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_dim=X_train.shape[1]))  # Hidden Layer 1\n",
    "model.add(Dense(64, activation='tanh'))  # Hidden Layer 2\n",
    "model.add(Dense(32, activation='relu'))  # Hidden Layer 3\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))  # Output Layer (Multi-class)\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "print(\"\\nModel Evaluation on Test Data:\")\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = y_pred_probs.argmax(axis=1)\n",
    "y_test_classes = y_test.argmax(axis=1)\n",
    "\n",
    "accuracy = accuracy_score(y_test_classes, y_pred)\n",
    "precision = precision_score(y_test_classes, y_pred, average='weighted')\n",
    "recall = recall_score(y_test_classes, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test_classes, y_pred, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81676cdf-890b-4288-b64d-6ba7f027a15f",
   "metadata": {},
   "source": [
    "## Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "48cdd95b-00d2-4632-b560-691b68e4d44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "eb04ef10-4d08-438e-aab5-f6e110ae51c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "238a192e-6d4e-4530-8453-2747ae190a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4600 entries, 0 to 4599\n",
      "Data columns (total 18 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   date           4600 non-null   object \n",
      " 1   price          4600 non-null   float64\n",
      " 2   bedrooms       4600 non-null   float64\n",
      " 3   bathrooms      4600 non-null   float64\n",
      " 4   sqft_living    4600 non-null   int64  \n",
      " 5   sqft_lot       4600 non-null   int64  \n",
      " 6   floors         4600 non-null   float64\n",
      " 7   waterfront     4600 non-null   int64  \n",
      " 8   view           4600 non-null   int64  \n",
      " 9   condition      4600 non-null   int64  \n",
      " 10  sqft_above     4600 non-null   int64  \n",
      " 11  sqft_basement  4600 non-null   int64  \n",
      " 12  yr_built       4600 non-null   int64  \n",
      " 13  yr_renovated   4600 non-null   int64  \n",
      " 14  street         4600 non-null   object \n",
      " 15  city           4600 non-null   object \n",
      " 16  statezip       4600 non-null   object \n",
      " 17  country        4600 non-null   object \n",
      "dtypes: float64(4), int64(9), object(5)\n",
      "memory usage: 647.0+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "809df032-be23-4424-ad56-32dda3baac7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>statezip</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-05-02 00:00:00</td>\n",
       "      <td>313000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1340</td>\n",
       "      <td>7912</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1340</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>2005</td>\n",
       "      <td>18810 Densmore Ave N</td>\n",
       "      <td>Shoreline</td>\n",
       "      <td>WA 98133</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-05-02 00:00:00</td>\n",
       "      <td>2384000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3650</td>\n",
       "      <td>9050</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3370</td>\n",
       "      <td>280</td>\n",
       "      <td>1921</td>\n",
       "      <td>0</td>\n",
       "      <td>709 W Blaine St</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA 98119</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-05-02 00:00:00</td>\n",
       "      <td>342000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1930</td>\n",
       "      <td>11947</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1930</td>\n",
       "      <td>0</td>\n",
       "      <td>1966</td>\n",
       "      <td>0</td>\n",
       "      <td>26206-26214 143rd Ave SE</td>\n",
       "      <td>Kent</td>\n",
       "      <td>WA 98042</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-05-02 00:00:00</td>\n",
       "      <td>420000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2000</td>\n",
       "      <td>8030</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1963</td>\n",
       "      <td>0</td>\n",
       "      <td>857 170th Pl NE</td>\n",
       "      <td>Bellevue</td>\n",
       "      <td>WA 98008</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-05-02 00:00:00</td>\n",
       "      <td>550000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1940</td>\n",
       "      <td>10500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1140</td>\n",
       "      <td>800</td>\n",
       "      <td>1976</td>\n",
       "      <td>1992</td>\n",
       "      <td>9105 170th Ave NE</td>\n",
       "      <td>Redmond</td>\n",
       "      <td>WA 98052</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date      price  bedrooms  bathrooms  sqft_living  sqft_lot  \\\n",
       "0  2014-05-02 00:00:00   313000.0       3.0       1.50         1340      7912   \n",
       "1  2014-05-02 00:00:00  2384000.0       5.0       2.50         3650      9050   \n",
       "2  2014-05-02 00:00:00   342000.0       3.0       2.00         1930     11947   \n",
       "3  2014-05-02 00:00:00   420000.0       3.0       2.25         2000      8030   \n",
       "4  2014-05-02 00:00:00   550000.0       4.0       2.50         1940     10500   \n",
       "\n",
       "   floors  waterfront  view  condition  sqft_above  sqft_basement  yr_built  \\\n",
       "0     1.5           0     0          3        1340              0      1955   \n",
       "1     2.0           0     4          5        3370            280      1921   \n",
       "2     1.0           0     0          4        1930              0      1966   \n",
       "3     1.0           0     0          4        1000           1000      1963   \n",
       "4     1.0           0     0          4        1140            800      1976   \n",
       "\n",
       "   yr_renovated                    street       city  statezip country  \n",
       "0          2005      18810 Densmore Ave N  Shoreline  WA 98133     USA  \n",
       "1             0           709 W Blaine St    Seattle  WA 98119     USA  \n",
       "2             0  26206-26214 143rd Ave SE       Kent  WA 98042     USA  \n",
       "3             0           857 170th Pl NE   Bellevue  WA 98008     USA  \n",
       "4          1992         9105 170th Ave NE    Redmond  WA 98052     USA  "
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "cdf7bef1-4ca1-4fd0-8eff-9617223e4913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.600000e+03</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4.600000e+03</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.519630e+05</td>\n",
       "      <td>3.400870</td>\n",
       "      <td>2.160815</td>\n",
       "      <td>2139.346957</td>\n",
       "      <td>1.485252e+04</td>\n",
       "      <td>1.512065</td>\n",
       "      <td>0.007174</td>\n",
       "      <td>0.240652</td>\n",
       "      <td>3.451739</td>\n",
       "      <td>1827.265435</td>\n",
       "      <td>312.081522</td>\n",
       "      <td>1970.786304</td>\n",
       "      <td>808.608261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.638347e+05</td>\n",
       "      <td>0.908848</td>\n",
       "      <td>0.783781</td>\n",
       "      <td>963.206916</td>\n",
       "      <td>3.588444e+04</td>\n",
       "      <td>0.538288</td>\n",
       "      <td>0.084404</td>\n",
       "      <td>0.778405</td>\n",
       "      <td>0.677230</td>\n",
       "      <td>862.168977</td>\n",
       "      <td>464.137228</td>\n",
       "      <td>29.731848</td>\n",
       "      <td>979.414536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>370.000000</td>\n",
       "      <td>6.380000e+02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>370.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1900.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.228750e+05</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>5.000750e+03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1190.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1951.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.609435e+05</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>1980.000000</td>\n",
       "      <td>7.683000e+03</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1590.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1976.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.549625e+05</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2620.000000</td>\n",
       "      <td>1.100125e+04</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2300.000000</td>\n",
       "      <td>610.000000</td>\n",
       "      <td>1997.000000</td>\n",
       "      <td>1999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.659000e+07</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13540.000000</td>\n",
       "      <td>1.074218e+06</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9410.000000</td>\n",
       "      <td>4820.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              price     bedrooms    bathrooms   sqft_living      sqft_lot  \\\n",
       "count  4.600000e+03  4600.000000  4600.000000   4600.000000  4.600000e+03   \n",
       "mean   5.519630e+05     3.400870     2.160815   2139.346957  1.485252e+04   \n",
       "std    5.638347e+05     0.908848     0.783781    963.206916  3.588444e+04   \n",
       "min    0.000000e+00     0.000000     0.000000    370.000000  6.380000e+02   \n",
       "25%    3.228750e+05     3.000000     1.750000   1460.000000  5.000750e+03   \n",
       "50%    4.609435e+05     3.000000     2.250000   1980.000000  7.683000e+03   \n",
       "75%    6.549625e+05     4.000000     2.500000   2620.000000  1.100125e+04   \n",
       "max    2.659000e+07     9.000000     8.000000  13540.000000  1.074218e+06   \n",
       "\n",
       "            floors   waterfront         view    condition   sqft_above  \\\n",
       "count  4600.000000  4600.000000  4600.000000  4600.000000  4600.000000   \n",
       "mean      1.512065     0.007174     0.240652     3.451739  1827.265435   \n",
       "std       0.538288     0.084404     0.778405     0.677230   862.168977   \n",
       "min       1.000000     0.000000     0.000000     1.000000   370.000000   \n",
       "25%       1.000000     0.000000     0.000000     3.000000  1190.000000   \n",
       "50%       1.500000     0.000000     0.000000     3.000000  1590.000000   \n",
       "75%       2.000000     0.000000     0.000000     4.000000  2300.000000   \n",
       "max       3.500000     1.000000     4.000000     5.000000  9410.000000   \n",
       "\n",
       "       sqft_basement     yr_built  yr_renovated  \n",
       "count    4600.000000  4600.000000   4600.000000  \n",
       "mean      312.081522  1970.786304    808.608261  \n",
       "std       464.137228    29.731848    979.414536  \n",
       "min         0.000000  1900.000000      0.000000  \n",
       "25%         0.000000  1951.000000      0.000000  \n",
       "50%         0.000000  1976.000000      0.000000  \n",
       "75%       610.000000  1997.000000   1999.000000  \n",
       "max      4820.000000  2014.000000   2014.000000  "
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "673c568b-1835-4073-8118-62937520f4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=[\"date\", \"street\", \"city\", \"statezip\", \"country\"])\n",
    "\n",
    "data_features = data.drop(columns=[\"price\"])\n",
    "data_target = data[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "43604189-045e-4618-ab3e-c71fd62a8baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "data_features = scaler.fit_transform(data_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "9e2db9db-3340-4821-82f4-de8885cd1a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_features, data_target, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "7880d4b9-f4a9-47a0-9927-2b2ea77f3e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 446169088000.0000 - mean_squared_error: 446169088000.0000 - val_loss: 401454661632.0000 - val_mean_squared_error: 401454661632.0000\n",
      "Epoch 2/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - loss: 428027805696.0000 - mean_squared_error: 428027805696.0000 - val_loss: 401345413120.0000 - val_mean_squared_error: 401345413120.0000\n",
      "Epoch 3/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - loss: 450973171712.0000 - mean_squared_error: 450973171712.0000 - val_loss: 401185079296.0000 - val_mean_squared_error: 401185079296.0000\n",
      "Epoch 4/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - loss: 449342439424.0000 - mean_squared_error: 449342439424.0000 - val_loss: 400971038720.0000 - val_mean_squared_error: 400971038720.0000\n",
      "Epoch 5/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - loss: 466372034560.0000 - mean_squared_error: 466372034560.0000 - val_loss: 400703913984.0000 - val_mean_squared_error: 400703913984.0000\n",
      "Epoch 6/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - loss: 434318147584.0000 - mean_squared_error: 434318147584.0000 - val_loss: 400383344640.0000 - val_mean_squared_error: 400383344640.0000\n",
      "Epoch 7/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - loss: 432996810752.0000 - mean_squared_error: 432996810752.0000 - val_loss: 400011558912.0000 - val_mean_squared_error: 400011558912.0000\n",
      "Epoch 8/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - loss: 423314128896.0000 - mean_squared_error: 423314128896.0000 - val_loss: 399590326272.0000 - val_mean_squared_error: 399590326272.0000\n",
      "Epoch 9/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - loss: 419558064128.0000 - mean_squared_error: 419558064128.0000 - val_loss: 399120072704.0000 - val_mean_squared_error: 399120072704.0000\n",
      "Epoch 10/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - loss: 458448928768.0000 - mean_squared_error: 458448928768.0000 - val_loss: 398602993664.0000 - val_mean_squared_error: 398602993664.0000\n",
      "Epoch 11/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 408866881536.0000 - mean_squared_error: 408866881536.0000 - val_loss: 398040956928.0000 - val_mean_squared_error: 398040956928.0000\n",
      "Epoch 12/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 887us/step - loss: 453083529216.0000 - mean_squared_error: 453083529216.0000 - val_loss: 397436944384.0000 - val_mean_squared_error: 397436944384.0000\n",
      "Epoch 13/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - loss: 497932697600.0000 - mean_squared_error: 497932697600.0000 - val_loss: 396788072448.0000 - val_mean_squared_error: 396788072448.0000\n",
      "Epoch 14/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - loss: 427663622144.0000 - mean_squared_error: 427663622144.0000 - val_loss: 396099944448.0000 - val_mean_squared_error: 396099944448.0000\n",
      "Epoch 15/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - loss: 444008660992.0000 - mean_squared_error: 444008660992.0000 - val_loss: 395368464384.0000 - val_mean_squared_error: 395368464384.0000\n",
      "Epoch 16/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - loss: 418340929536.0000 - mean_squared_error: 418340929536.0000 - val_loss: 394601529344.0000 - val_mean_squared_error: 394601529344.0000\n",
      "Epoch 17/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - loss: 465536811008.0000 - mean_squared_error: 465536811008.0000 - val_loss: 393795764224.0000 - val_mean_squared_error: 393795764224.0000\n",
      "Epoch 18/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - loss: 441224462336.0000 - mean_squared_error: 441224462336.0000 - val_loss: 392955854848.0000 - val_mean_squared_error: 392955854848.0000\n",
      "Epoch 19/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - loss: 455130316800.0000 - mean_squared_error: 455130316800.0000 - val_loss: 392080392192.0000 - val_mean_squared_error: 392080392192.0000\n",
      "Epoch 20/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - loss: 442593017856.0000 - mean_squared_error: 442593017856.0000 - val_loss: 391169671168.0000 - val_mean_squared_error: 391169671168.0000\n",
      "Epoch 21/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - loss: 455432437760.0000 - mean_squared_error: 455432437760.0000 - val_loss: 390224904192.0000 - val_mean_squared_error: 390224904192.0000\n",
      "Epoch 22/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - loss: 424400257024.0000 - mean_squared_error: 424400257024.0000 - val_loss: 389251301376.0000 - val_mean_squared_error: 389251301376.0000\n",
      "Epoch 23/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - loss: 430040907776.0000 - mean_squared_error: 430040907776.0000 - val_loss: 388245749760.0000 - val_mean_squared_error: 388245749760.0000\n",
      "Epoch 24/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - loss: 440270159872.0000 - mean_squared_error: 440270159872.0000 - val_loss: 387207561216.0000 - val_mean_squared_error: 387207561216.0000\n",
      "Epoch 25/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - loss: 430953365504.0000 - mean_squared_error: 430953365504.0000 - val_loss: 386134835200.0000 - val_mean_squared_error: 386134835200.0000\n",
      "Epoch 26/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - loss: 406685417472.0000 - mean_squared_error: 406685417472.0000 - val_loss: 385047822336.0000 - val_mean_squared_error: 385047822336.0000\n",
      "Epoch 27/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - loss: 461062471680.0000 - mean_squared_error: 461062471680.0000 - val_loss: 383920570368.0000 - val_mean_squared_error: 383920570368.0000\n",
      "Epoch 28/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - loss: 455581859840.0000 - mean_squared_error: 455581859840.0000 - val_loss: 382775099392.0000 - val_mean_squared_error: 382775099392.0000\n",
      "Epoch 29/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - loss: 431033188352.0000 - mean_squared_error: 431033188352.0000 - val_loss: 381595975680.0000 - val_mean_squared_error: 381595975680.0000\n",
      "Epoch 30/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - loss: 394544971776.0000 - mean_squared_error: 394544971776.0000 - val_loss: 380390637568.0000 - val_mean_squared_error: 380390637568.0000\n",
      "Epoch 31/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - loss: 418895626240.0000 - mean_squared_error: 418895626240.0000 - val_loss: 379166031872.0000 - val_mean_squared_error: 379166031872.0000\n",
      "Epoch 32/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - loss: 420785094656.0000 - mean_squared_error: 420785094656.0000 - val_loss: 377916915712.0000 - val_mean_squared_error: 377916915712.0000\n",
      "Epoch 33/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - loss: 414478008320.0000 - mean_squared_error: 414478008320.0000 - val_loss: 376640339968.0000 - val_mean_squared_error: 376640339968.0000\n",
      "Epoch 34/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - loss: 402023907328.0000 - mean_squared_error: 402023907328.0000 - val_loss: 375336271872.0000 - val_mean_squared_error: 375336271872.0000\n",
      "Epoch 35/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - loss: 415272861696.0000 - mean_squared_error: 415272861696.0000 - val_loss: 374014410752.0000 - val_mean_squared_error: 374014410752.0000\n",
      "Epoch 36/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - loss: 420431298560.0000 - mean_squared_error: 420431298560.0000 - val_loss: 372677345280.0000 - val_mean_squared_error: 372677345280.0000\n",
      "Epoch 37/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - loss: 410104496128.0000 - mean_squared_error: 410104496128.0000 - val_loss: 371314393088.0000 - val_mean_squared_error: 371314393088.0000\n",
      "Epoch 38/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step - loss: 449636270080.0000 - mean_squared_error: 449636270080.0000 - val_loss: 369918541824.0000 - val_mean_squared_error: 369918541824.0000\n",
      "Epoch 39/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - loss: 411432550400.0000 - mean_squared_error: 411432550400.0000 - val_loss: 368509485056.0000 - val_mean_squared_error: 368509485056.0000\n",
      "Epoch 40/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - loss: 389493489664.0000 - mean_squared_error: 389493489664.0000 - val_loss: 367091023872.0000 - val_mean_squared_error: 367091023872.0000\n",
      "Epoch 41/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - loss: 381725507584.0000 - mean_squared_error: 381725507584.0000 - val_loss: 365643431936.0000 - val_mean_squared_error: 365643431936.0000\n",
      "Epoch 42/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - loss: 415134384128.0000 - mean_squared_error: 415134384128.0000 - val_loss: 364170608640.0000 - val_mean_squared_error: 364170608640.0000\n",
      "Epoch 43/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 437759377408.0000 - mean_squared_error: 437759377408.0000 - val_loss: 362689298432.0000 - val_mean_squared_error: 362689298432.0000\n",
      "Epoch 44/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 420455120896.0000 - mean_squared_error: 420455120896.0000 - val_loss: 361182691328.0000 - val_mean_squared_error: 361182691328.0000\n",
      "Epoch 45/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - loss: 389124947968.0000 - mean_squared_error: 389124947968.0000 - val_loss: 359655178240.0000 - val_mean_squared_error: 359655178240.0000\n",
      "Epoch 46/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - loss: 409753616384.0000 - mean_squared_error: 409753616384.0000 - val_loss: 358111444992.0000 - val_mean_squared_error: 358111444992.0000\n",
      "Epoch 47/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - loss: 359688601600.0000 - mean_squared_error: 359688601600.0000 - val_loss: 356562829312.0000 - val_mean_squared_error: 356562829312.0000\n",
      "Epoch 48/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - loss: 383596789760.0000 - mean_squared_error: 383596789760.0000 - val_loss: 354976104448.0000 - val_mean_squared_error: 354976104448.0000\n",
      "Epoch 49/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - loss: 408945590272.0000 - mean_squared_error: 408945590272.0000 - val_loss: 353392394240.0000 - val_mean_squared_error: 353392394240.0000\n",
      "Epoch 50/50\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - loss: 378669989888.0000 - mean_squared_error: 378669989888.0000 - val_loss: 351769788416.0000 - val_mean_squared_error: 351769788416.0000\n",
      "\n",
      "Model Evaluation on Test Data:\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713us/step - loss: 532797587456.0000 - mean_squared_error: 532797587456.0000\n",
      "Test Loss (MSE): 1302759342080.0\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Mean Squared Error (MSE): 1302759180105.6538\n",
      "Mean Absolute Error (MAE): 532844.9447278026\n",
      "R2 Score: -0.2774073200033029\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_dim=X_train.shape[1]))  # Hidden Layer 1\n",
    "model.add(Dense(64, activation='tanh'))  # Hidden Layer 2\n",
    "model.add(Dense(32, activation='relu'))  # Hidden Layer 3\n",
    "model.add(Dense(1, activation='linear'))  # Output Layer for Regression\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "print(\"\\nModel Evaluation on Test Data:\")\n",
    "test_loss, test_mse = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss (MSE): {test_loss}\")\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"R2 Score: {r2}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
